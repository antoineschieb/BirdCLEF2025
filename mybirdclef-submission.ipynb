{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0acf54",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-02T08:05:38.838803Z",
     "iopub.status.busy": "2025-05-02T08:05:38.838493Z",
     "iopub.status.idle": "2025-05-02T08:05:51.174513Z",
     "shell.execute_reply": "2025-05-02T08:05:51.173289Z"
    },
    "papermill": {
     "duration": 12.34094,
     "end_time": "2025-05-02T08:05:51.176374",
     "exception": false,
     "start_time": "2025-05-02T08:05:38.835434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "import sys\n",
    "# sys.path.append('/kaggle/input/bird-clef-utils')\n",
    "from utils import EffNetB0Classifier, process_spectrogram\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = \"cpu\"\n",
    "\n",
    "label_map = json.load(open('label_map.json'))\n",
    "# Class labels from train audio\n",
    "class_labels = sorted(list(label_map.keys()))\n",
    "\n",
    "# List of test soundscapes (only visible during submission)\n",
    "test_soundscape_path = '/kaggle/input/birdclef-2025/train_soundscapes'\n",
    "# test_soundscape_path = 'train_soundscapes'\n",
    "test_soundscapes = [os.path.join(test_soundscape_path, afile) for afile in sorted(os.listdir(test_soundscape_path)) if afile.endswith('.ogg')]\n",
    "\n",
    "# Open each soundscape and make predictions for 5-second segments\n",
    "# Use pandas df with 'row_id' plus class labels as columns\n",
    "predictions = pd.DataFrame(columns=['row_id'] + class_labels)\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "model = EffNetB0Classifier(num_classes=206)\n",
    "model.load_state_dict(torch.load(\"/kaggle/input/first-try/pytorch/default/7/my_model.pth\", map_location=torch.device('cpu'), weights_only=True))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "for soundscape in test_soundscapes:\n",
    "    # Load audio\n",
    "    sig, rate = librosa.load(path=soundscape, sr=None)\n",
    "\n",
    "    # Split into 5-second chunks\n",
    "    chunks = []\n",
    "    for i in range(0, len(sig), rate * 5):\n",
    "        chunk = sig[i:i + rate * 5]\n",
    "        if len(chunk) < rate * 5:  # Pad the chunk if it's less than 5 seconds\n",
    "            chunk = np.pad(chunk, (0, rate * 5 - len(chunk)), mode='constant')\n",
    "        chunks.append(chunk)\n",
    "\n",
    "    # Make predictions for each chunk\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        # Compute the spectrogram\n",
    "        spectrogram = librosa.feature.melspectrogram(y=chunk, sr=rate, n_mels=128)\n",
    "        spectrogram_db = librosa.power_to_db(spectrogram, ref=np.max)\n",
    "        spectrogram_tensor = process_spectrogram(spectrogram_db)\n",
    "        \n",
    "        # Get row id (soundscape id + end time of 5s chunk)\n",
    "        row_id = os.path.basename(soundscape).split('.')[0] + f'_{i * 5 + 5}'\n",
    "\n",
    "        # Make prediction\n",
    "        with torch.no_grad():\n",
    "            logits = model(spectrogram_tensor.unsqueeze(0))\n",
    "            predictions_array = (logits > 0).int().squeeze().cpu().numpy()\n",
    "\n",
    "        # Append to predictions as new row\n",
    "        new_row = pd.DataFrame([[row_id] + list(predictions_array)], columns=['row_id'] + class_labels)\n",
    "        predictions = pd.concat([predictions, new_row], axis=0, ignore_index=True)\n",
    "\n",
    "# Save prediction as csv\n",
    "predictions.to_csv('submission.csv', index=False)\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 11361821,
     "sourceId": 91844,
     "sourceType": "competition"
    },
    {
     "datasetId": 7305593,
     "sourceId": 11647876,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 324619,
     "modelInstanceId": 304144,
     "sourceId": 366843,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 324619,
     "modelInstanceId": 304144,
     "sourceId": 368061,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 324619,
     "modelInstanceId": 304144,
     "sourceId": 368487,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 324619,
     "modelInstanceId": 304144,
     "sourceId": 369278,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30918,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "birdclef-2025-YT0uVT6V-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17.855052,
   "end_time": "2025-05-02T08:05:53.106156",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-02T08:05:35.251104",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
